Transcription de ia_open_source 
Fait le  

[0.00s - 106.34s]  Aujourd'hui, on reçoit une légende de la tech française, Arthur Mench, cofondateur de Mistral AI, la seule entreprise d'Europe capable de tenir tête à OpenAI et aux GAFAM dans leur course à l'intelligence artificielle. En à peine un an, lui et ses deux associés ont réussi l'impossible, lever plus d'un milliard d'euros, développer des modèles d'IA qui rivalisent avec Chagipity et transformer leur start-up parisienne en une entreprise valorisée 6 milliards d'euros. Dans cet épisode exceptionnel, Arthur va nous dévoiler les secrets de cette success story, comment trois Français ont quitté leur job en or chez Google et Meta pour se lancer dans cette aventure folle, comment ils rivalisent avec des géants qui ont 100 fois plus de puissance de calcul qu'eux et surtout la guerre des talents qui fait rage en coulisses entre Mistral et les GAFAM pour attirirer les meilleurs ingénieurs on va aussi lui demander si d'après lui les modèles dia ont atteint un plafond et qu'est ce qui nous réserve pour la suite je suis très excité et honoré de pouvoir vous partager cette conversation avec arthur mensch mais juste avant j'ai un message pour tous ceux qui hésitent à prendre un abonnement chat gpt notre partenaire du jour mammouth ayammouth AI, a eu une idée assez brillante. Rassembler tous les meilleurs modèles d'IAD dans une seule interface et derrière un unique abonnement. Pour 10 euros par mois, vous avez accès aux modèles de langages les plus récents, O1, Grock, DeepSync et même des modèles de génération d'images comme Midjournay ou Flux. Quand on sait que cumuler tous ces abonnements, ça coûterait dans les 80-100 euros, c'est assez imbattable. Si vous avez besoin de générer beaucoup d'images par mois, ils ont aussi des plans un peu plus chers. Le truc cool, c'est qu'ils sont toujours à l'affût des nouvelles sorties. Par exemple, ils ont déjà un flux pour la génération d'images. Et globalement, c'est juste agréable de ne pas avoir à changer d'interface tout le temps. Je vous mets le lien vers leurs différentes formules en description et on reprend. C'est quoi l'élément déclencheur déjà pour se dire « on va créer notre propre société face à ces géants, quand on est déjà bien installé, confortable.
[106.58s - 108.26s]  Je pense qu'il y a deux conversations,
[108.52s - 110.10s]  une en septembre 2022 avec Timothée,
[110.26s - 112.52s]  et une en novembre 2022 à NeurIPS,
[112.64s - 116.06s]  qui est la grosse conférence de machine learning avec Guillaume,
[116.30s - 118.64s]  où on s'est rendu compte qu'on avait des aspirations similaires
[118.64s - 121.62s]  de lancer une entreprise en France,
[121.78s - 123.94s]  et qu'on connaissait pas mal de gens que ça intéresserait.
[124.50s - 127.48s]  Et donc à partir de là, c'est un peu le début de l'engrenage.
[127.62s - 129.42s]  C'est-à-dire qu'au début, tu te dis, c'est peut-être une bonne idée.
[130.06s - 132.10s]  Et puis au fur et à mesure, chaque jour qui passe,
[132.36s - 134.68s]  tu t'impliques de plus en plus émotionnellement dans cette idée.
[135.12s - 136.74s]  Puis à un moment donné, tu as un peu un point de non-retour
[136.74s - 140.28s]  parce qu'en fait, tu es plus dans l'idée que dans le travail dans ton entreprise actuelle.
[140.64s - 143.38s]  Mais à partir de février, c'est vrai qu'on s'est dit,
[143.84s - 425.60s]  là, on peut avoir 15 personnes, on peut aller vite, on sait le faire. On peut démontrer que l'Europe peut faire des choses intéressantes dans le domaine et peut reprendre une position de leadership. Et donc c'est comme ça que ça s'est fait et à partir d'avril, on s'est lancé. Donc Tho, il y a déjà cette idée que le projet c'est de faire de l'IA très performante européenne. Plus ça que, juste on se sent un petit peu peut-être ralenti par une grosse structure au-dessus de nous, donc Meta, Google, et on pense aller plus vite tout seul. C'était quoi ? Bon, t'avais les deux. En fait, on met, Guillaume, Timothée et moi, on travaillait sur ce sujet depuis à peu près 2020, et on a vu ce qu'on pouvait faire avec des petites équipes très concentrées. C'est vrai qu'en 2022, ces équipes sont devenues moins concentrées parce que c'est le moment où le monde a réalisé qu'il y avait une opportunité économique autour des modèles de langue. Et donc, on s'est dit qu'on pouvait bénéficier aussi de cet aspect de désorganisation pour nous être mieux organisés et fournir des choses plus rapidement. Ça se passe comment au tout début ? Vous avez chacun un peu une spécialité. Comment vous vous organisez au tout début de la boîte ? On vient tous les trois de la même formation. On a fait la même chose, on a tous les trois des thèses en machine learning. C'est vrai qu'on s'est rapidement spécialisé avec Guillaume, qui est le scientifique le plus fort d'entre nous, qui a pris la partie scientifique. Timothée, qui est plus un ingénieur et qui s'est occupé de faire toute l'infrastructure et de monter l'équipe d'ingénieurs produits aussi. Et moi, j'ai assez vite fait l'aspect levée de fonds, l'aspect parler avec des clients. C'est des choses que j'aimais bien faire. On s'est répartis comme ça assez vite. Et pour revenir à comment ça démarre, ça démarre par une levée de fonds, parce qu'il faut la capacité de calcul et il faut la capacité humaine pour avancer assez vite. Et donc, on a fait une levée de fonds en quelques semaines et à partir de là, on était partis pour faire le premier modèle en septembre. C'est-à-dire qu'il n'y a pas une seule ligne de code, en fait, avant même de savoir que c'est bon, il y a une levée de fonds qui va se faire. C'est un domaine où il faut forcément attendre la levée de fonds si on veut commencer la première... Tu peux un peu paralléliser, commencer à faire du code, mais à trois, tu n'as pas beaucoup de leviers. Il vaut mieux avoir une petite équipe d'une dizaine de personnes pour aller plus vite. On a commencé par la data, parce qu'il faut la donner pour entraîner les modèles. Il y a beaucoup de travail aussi manuel là-dessus à faire. Et Guillaume, Timothée, essentiellement, avaient commencé pendant qu'on finissait la levée. On parle des levées de fonds. Toi, tu as fait Polytechnique, Centraire de Paris, l'UNS et un doctorat. Est-ce que ça aide quand même à lever des fonds alors que vous n'êtes que trois ? Ou alors est-ce que c'est encore plus le nom méta Google ? Tu dirais que c'est quoi qui aide le plus ? Je pense que ce qui a aidé au démarrage, c'est qu'on était crédibles sur le domaine le plus chaud du moment en 2023 et qu'on avait plutôt des papiers qui étaient liés à ce domaine-là. C'est-à-dire que moi, j'étais dans l'équipe qui travaillait à DeepMind là-dessus. Guillaume et Timothée, ils étaient à Meta. C'est eux qui ont fait de la malle au premier. Et donc, cette crédibilité-là, ce n'est pas ce qu'on a fait dans notre jeunesse à l'école. C'est plutôt une crédibilité scientifique qu'on a construite dans notre première partie de carrière, on va dire. Un alignement de planète avec ce qui intéresse le plus et les meilleures personnes pour le développer, en fait. Oui, effectivement, notre crédibilité venait aussi du fait qu'on avait une excellente équipe de démarche et qu'on pouvait démontrer qu'on saurait la recruter. Et il y a ce jour qui arrive, c'est le 27 septembre 2023, où vous postez un lien sur votre compte Twitter parfaitement inactif et c'est votre premier modèle en fait. Donc Mistral 7B. Le tweet est vu plus d'un million de fois. Vous êtes repris par tous les médias américains, tout le monde de l'IA est en effervescence et s'amuse avec le modèle. Il est téléchargé un million de fois mais super vite. Nous, on a vu ça de l'extérieur. On a vu cet engouement. Vous, de l'intérieur, c'était comment ? Alors déjà, déjà le tweet c'était une idée de Guy Aumain, donc le chief scientist pour rendre à César ce qui appartient à César parce que vous ne le publiez pas comme les autres on ne le publie pas comme les autres, effectivement on a mis à disposition un magnet link qui permet de le télécharger en BitTorrent, c'est comme ça qu'on a parlé la première fois et c'était une excellente idée c'était une journée où on avait aussi aussi prévu de faire de la communication plus habituelle. J'étais allé parler aux journalistes Figaro, etc. Il fallait mettre le torrent le matin et puis l'embargo était vers 16h. Il y avait cette période où on avait rompu l'embargo mais les journalistes, à priori, n'allaient pas comprendre ce qui se passait, donc ça se passait bien. C'est moi qui postais, je crois que c'était à 5h du mat, donc j'avais mis un petit réveil, parce que j'étais pas sûr du schedule send de Twitter, qui s'appelait encore Twitter à l'époque, et je l'ai mis, et je suis allé me recoucher, et ensuite, on a vu que ça avait bien démarré au démarrage. C'est un truc où vous vous y attendiez un petit peu, ou quand même... On savait que le modèle était bon, on savait que on était largement au-dessus des meilleurs modèles open source,
[426.06s - 427.76s]  qu'on avait visé
[427.76s - 429.98s]  explicitement cette taille-là, parce qu'on savait que ça tournait
[429.98s - 431.94s]  sur des laptops aussi. Donc, ça
[431.94s - 433.86s]  voulait dire que tous les hobbyistes
[433.86s - 436.30s]  allaient pouvoir jouer avec, et ça n'a pas manqué, ça a fonctionné.
[436.76s - 438.00s]  Donc, on se doutait
[438.00s - 439.88s]  qu'on allait être remarqué. Ce qu'on
[439.88s - 442.10s]  ne se doutait pas, c'est que les gens allaient le mettre dans des perroquies
[442.10s - 443.18s]  en peluche, ce genre de choses,
[443.40s - 705.60s]  en un mois. La réception était plus grande que ce qu'on espérait, on était très contents. Il y a un autre truc qui s'est passé nécessairement en publiant des modèles avec des poids ouverts comme ça, c'est que ça laisse la porte à tout ce qui est entraînement, fine-tuning et tout le monde s'en est donné à cœur joie. Je pense que c'était déjà un peu le cas sur les modèles de Yamaha, mais je me souviens que c'est un modèle qui a été beaucoup, beaucoup réentraîné. C'est quoi les fine-tuning un peu étonnants ou curieux dont tu te souviens de ce modèle-là ou d'autres ? Il y a quelqu'un qui s'appelle Technium qui nous avait entraîné ce modèle pour parler aux morts. Je ne sais plus comment ça s'appelait, mais il avait fait un fine-tuning un petit peu ésotérique, et le truc marchait relativement bien, donc c'était assez marrant. C'est vrai que cette taille-là, c'est aussi une taille où tu peux fine-tuner même sur des gros PC de gaming, éventuellement. Et puis, ça ne coûte pas très cher et ça permet de rentrer du style. Ça permet de faire du roleplay. Et donc, les gens se sont donnés à cœur de joie, effectivement. Parce que, du coup, pour expliquer, il y a le modèle de fondation qui est, lui, le plus coûteux et le plus compliqué. Et j'imagine qu'il contient, en gros, l'information. Et après, le fine-tuning, c'est conversationnel. C'est en faire un bon agent de discussion. Oui, il faut voir la première phase comme une compression de la connaissance humaine. Et la deuxième phase comme une manière d'instruire le modèle à suivre ce qu'on lui demande de faire. Donc, on le rend contrôlable. Et une manière de le contrôler, c'est de le rendre conversationnel. Donc, ces deux phases-là sont assez distinctes, effectivement. Et est-ce que sur cette deuxième phase, il y a des trucs d'indépendants, tout seuls, qui ont testé des choses sur du fine-tuning et ont découvert des bonnes techniques ? Ouais, on a appris des trucs, alors je ne vais pas rentrer dans les détails, mais il y avait de direct preference optimization, c'est un peu du jargon, mais qu'on n'avait pas fait sur le premier modèle et on a vu des gens le faire, on s'est dit devrait bien marcher sur le deuxième modèle. Et ça a bien marché sur le deuxième modèle. Maintenant, on fait d'autres choses. Mais effectivement, une des raisons pour lesquelles on a lancé la boîte, au-delà de l'Europe, etc., c'est aussi l'aspect ouvert et l'aspect contribution de la communauté. En fait, l'EI, entre 2012 et 2022, ça s'est construit les uns par-dessus les autres, pendant les conférences, les grosses boîtes par-dessus les grosses boîtes. Puis soudain, quand c'est devenu un modèle économique intéressant, les gens ont arrêté, les grosses entreprises ont arrêté. Et donc, on a essayé de prolonger ça un peu avec ce qu'on a fait. Aujourd'hui, tu as vraiment des deux camps distincts. C'est assez particulier. D'un côté, les Anthropik, l'OpenAI et les compagnies qui ne publient plus grand ne publient plus grand chose Google aussi j'ai l'impression a beaucoup ralenti les publications et de l'autre côté les Chinois bizarrement pourquoi les Chinois ils sont autant à fond dans les modèles Open Source c'est quand même curieux non ? Je pense qu'ils sont en position de Challenger ce que l'Open Source c'est une bonne stratégie de Challenger on en est je pense la bonne illustration je pense qu'ils ont des bonnes techniques, ils ont des bons renseignements aussi. Mais ils ont beaucoup fait avancer la science, les nouvelles techniques. C'est clairement ceux qui publient le plus, effectivement. Et tu parlais de la position de Challenger. Est-ce que Meta, quand il publie Yama pour la première fois, ils sont en position de Challenger à ce moment-là ? C'est les Timothée et Guillaume. Je pense que oui, ils sont en position de Challenger parce qu'ils n'ont pas encore parlé. Et je pense qu'avec le mouvement qu'on a perpétué avec nos modèles en septembre et en décembre en particulier, donc Mistral 7B, Mistral 8X 7B, je pense qu'on a lancé cette roue de l'open source. Et donc, il y a aussi un peu une concurrence sur qui fait les meilleurs modèles open source. Je pense que ça bénéficie à tout le monde. Et donc, on est ravi d'avoir bien participé à ça. Et qu'est-ce qui fait, tu penses qu'à ce moment-là, vous avez autant d'avance, vous ? Après, il y a un yo-yo avec tout le monde qui se produit, mais là, il y a une vraie avance indiscutable. Je pense qu'on connaissait l'importance de la donnée, et on a beaucoup travaillé là-dessus. On savait aussi comment entraîner le modèle de manière efficace, parce qu'on avait trois ondes d'expérience chacun dans ce domaine. Il y avait des bonnes connaissances et on a insisté sur les aspects de l'entraînement qui ont le plus de levier, c'est-à-dire la qualité de la donnée. C'est derrière un peu tout l'évolution de la recherche. J'ai l'impression de temps vert. En fait, il n'y a que la donnée qui compte. Grosse partie. La donnée et la quantité de calcul. Il y a aussi le compute. C'est lié à un autre sujet très important. C'est les fonds, tout simplement. En un an, vous avez en tout levé quand même un milliard d'euros, ce qui est vertigineux. Vous avez aussi sorti plein de nouveaux modèles, des PixRals, par exemple, des modèles un peu différents, multimodaux, etc. Comment vous approchez le fait que, justement, en termes de quantité de compute,
[705.92s - 707.44s]  par rapport à un méta, par exemple,
[708.18s - 710.30s]  qui aura, à la fin de l'année, 350 000
[710.30s - 712.06s]  H100, c'est ça ?
[712.06s - 713.24s]  Si je ne dis pas de bêtises.
[714.10s - 715.84s]  Est-ce que, justement, il n'y a pas le choix que de passer
[715.84s - 717.64s]  par des très grosses levées de fonds ?
[717.64s - 719.98s]  Mais après, comme on pérennise le truc, c'est quoi un peu ta vision
[719.98s - 721.86s]  du compute ? Nous, notre vision,
[721.98s - 723.78s]  c'est qu'on a besoin de compute, mais on n'a pas besoin de
[723.78s - 724.80s]  350 000 H100.
[1165.14s - 1167.82s]  Et donc, ça a été toujours notre test qu'on pouvait être plus efficace, qu'on pouvait, en étant focalisé sur le fait de faire des excellents produits et ne pas faire plein d'autres choses à côté, parce que nos concurrents américains ont tendance à faire beaucoup de choses à côté. L'allocation de ressources, c'est une question constante chez nous. C'est un peu le nerf de la guerre. Arriver à tenir l'amélioration des modèles dans le temps versus le cramage du compute. Il faut gérer le budget, il faut être intelligent pour ne pas dépenser trop. Tout est une question de mettre le curseur au bon endroit et d'avoir les bons compromis. Ce n'est pas facile, mais je pense que pour le moment, on a bien réussi. On a réussi à avoir des modèles qui sont très performants avec un niveau de dépense de capital qui est quand même très, très contrôlé. Est-ce que, justement, j'ai vu que parmi vos investisseurs dans les derniers rounds, je crois, il y a Nvidia. Est-ce que, justement, ça passe par des acteurs qui, eux, ont un peu le contrôle sur le hardware ou l'infrastructure ou les data centers ? Il y a Microsoft aussi, je crois, avec qui vous avez bossé. Est-ce que ça passe aussi par ça, justement, à s'entourer des bonnes personnes ? Il faut les bons partenaires. Il faut les bons partenaires de distribution en particulier parce que, en fait, le calcul, ça passe souvent par le cloud. Et donc, on a comme partenaire tous les fournisseurs de cloud américains parce que c'est quand même les plus gros. On a aussi des fournisseurs français, on a Outscale qui en travaille. Et puis Nvidia, c'est un fournisseur quasiment de cloud aussi, donc à ce titre, on travaille avec eux. On a aussi fait de la R&D avec un modèle qui s'appelle Mistral Nemo. Imagine, il y a des gens qui nous écoutent, qui n'ont pas su. Est-ce que tu peux nous expliquer, c'est quoi un peu aujourd'hui la gamme, les modèles qui sont à jour ? Moi, j'ai vu que dans les derniers mises à jour récents, il a le large 2 maintenant on les numérote comme Ubuntu donc 24.11 et donc celui-là, Mistral large 24.11, il est très fort pour appeler des fonctions, orchestrer des choses, parce qu'en fait les modèles ça génère du texte c'est l'utilisation de base mais ce qui est intéressant c'est quand ils génèrent des appels à des outils et qu'on les utilise comme des orchestrateurs comme un peu des operating systems et donc on travaille beaucoup sur le fait d'avoir des modèles qui puissent être connectés à plein d'outils différents auxquels on peut poser des questions auxquels on peut donner des tâches et qui vont réfléchir d'eux-mêmes aux outils qu'ils vont appeler et donc on insiste beaucoup là-dessus et donc la nouvelle version de Mistral Large elle est particulièrement forte là-dessus Après il y a eural aussi. Ça, pour comprendre, c'est plutôt pour servir, pour une entreprise par exemple, pour servir beaucoup d'utilisateurs en même temps ? C'est un autre type d'architecture qui est particulièrement pertinent quand on a une forte charge. Donc beaucoup d'utilisateurs, c'est des choses que nous, on utilise par exemple. Donc c'est Mixtral parce qu'en fait, c'est une sorte de cerbère à huit têtes. C'est ça, c'est plusieurs modèles en même temps, et chaque mot passe sur le modèle le plus adapté. Pour plusieurs raisons, ça permet de mieux utiliser les GPU. Et derrière, il y a les plus petits. Il y a les petits modèles qui passent sur les laptops, qui passent sur les smartphones, et ceux-là, ils sont particulièrement adaptés à des usages de hobbyistes, parce qu'il n'y a pas besoin d'aller dans le cloud, on peut les modifier facilementment et puis ils vont très vite. C'est aussi pas mal focalisé sur cet aspect petit et rapide parce que c'est vraiment l'ADN de l'entreprise. Aujourd'hui, le produit, ce n'est pas le modèle. Le produit, c'est la plateforme pour les développeurs et donc ils choisissent s'ils veulent aller vite et être moins intelligents ou aller lentement et être plus intelligents essentiellement. Et puis l'autre produit, c'est le chat. C'est une solution plus front-end qui permet aux entreprises de gérer leurs connaissances, d'automatiser des choses, qui permet à tous les utilisateurs, vous pouvez le tester aujourd'hui, d'accéder au web, de discuter de l'information, de générer du code, de générer des images, de créer des documents. On a un mode où l'interface évolue en fonction de l'intention de l'utilisateur. Donc ça, c'est une nouvelle interface home machine et on investit beaucoup là-dessus. Donc le produit, c'est la plateforme pour construire des applications en tant que développeur. Et là-dedans, il y a des modèles. Et puis, un ensemble d'applications qui permettent de gagner en productivité. C'est un milieu qui est super compétitif, évidemment. Que ce soit sur les modèles, mais aussi sur tout ce qu'il y a autour, sur comment améliorer l'expérience, les interfaces de chat, etc. On a vu les systèmes d'interface qui se bougent. Tout le monde est un peu en train d'essayer de trouver les meilleures solutions à ça, Anthropic, OpenAI, et vous, évidemment, en tant qu'outsider. C'est quoi votre cible précise à vous, en termes de possibilité d'évolution, quand on a des aussi gros acteurs à côté ? C'est quoi, toi, tu penses, la direction où vous avez un edge ? On a un fort edge dans le fait de découpler la question de l'infrastructure, de la question de l'interface. Notre solution, elle peut être déployée partout. Elle peut être déployée dans le cloud, mais elle peut être déployée chez les entreprises qui ne sont pas dans le cloud. Elle peut être déployée sur des laptops. C'est le edge qu'on a construit aussi au-dessus de l'aspect open source, que ça va assez bien avec. Que les poids des modèles soient accessibles, ça rend facile leur déploiement n'importe où. Donc on a cet aspect portabilité qui est très important. C'est notre première différenciation qu'on a beaucoup utilisée cette année. Et puis la différenciation qu'on cherche tous, c'est d'avoir la meilleure interface utilisateur. Et en fait, il y a plein de sujets qui ne sont pas résolus. Le fait d'utiliser plein d'outils en même temps, le fait d'avoir des agents qui tournent pendant longtemps et qui prennent le feedback des utilisateurs. C'est-à-dire qu'on peut les voir comme des stagiaires. Des stagiaires auxquels il faut faire du feedback pour qu'ils deviennent de plus en plus performants. Et donc, on va aller vers ce genre de système de plus en plus autonome, qui vont avoir besoin de plus en plus de feedback pour passer de 80% de performance à 100% de performance. Tout commence à dire que tu ne restes pas constamment derrière lui et attendre qu'il avance ? Non, tu lui donnes une tâche, tu regardes ce qu'il a fait, tu lui dis ce qu'il n'a pas bien fait, et puis ensuite, tu espères que la prochaine fois, il le fasse mieux. Mais en fait, c'est plein de questions scientifiques qu'il faut résoudre pour que ça fonctionne. Et d'interface. Et d'interface, oui. C'est pas du mail, en fait. Est-ce qu'on va pas... Pour l'instant, c'est du chat, en mode temps réel et tout ça. Est-ce qu'à terme, on va envoyer un mail à notre assistant, et juste, il nous ping quand il a fini, quoi ? C'est une des formes... Je pense que c'est plutôt l'assistant qui t'envoie un mail, en fait, à un moment donné. Tu y travailles, et puis toutes les deux heures, il dit, j'ai besoin de tuer, etc. Donc oui, il y a un aspect passé du synchrone à la synchrone qui est très important et qui pose plein de questions d'interface parce que le mail, c'est peut-être pas la meilleure interface. Il y en a certainement d'autres qui sont plus intelligentes. La question de quelle est l'interface pour donner le feedback, quelle est l'interface pour sélectionner ce qui est préférable pour l'humain, ça, on y travaille. J'all dire, je suis persuadé que, je ne sais pas, mais quand on regarde le chat, la discussion, ce n'est pas forcément l'interface du tout ultime pour dialoguer avec un LLM. Ça a beaucoup évolué. Maintenant, tu peux chatter avec le chat et puis il peut décider de te mettre dans un document et là, tu travailles avec lui sur la construction d'un document. Tu peux lui demander d'aller chercher des sources et tu vois les sources. Tu peux retourner, tu peux aller regarder ce que des humains ont écrit et demander des résumés, par exemple. En fait, ce que ça crée, ce que ça permet, les AI génératifs, c'est une espèce de liquidité de ta manière d'accéder à la connaissance. Tu peux regarder tout un site web et tu peux dire condense-moi ce site web en deux phrases. Je pense qu'il reste encore beaucoup de choses à faire pour que le modèle te permette d'apprendre beaucoup plus vite et de charger de la connaissance beaucoup plus vite. Je ne sais pas si tu as vu, mais je crois que c'est Vercel qui avait fait des démos assez marrantes de composants web qui se construisaient en fonction de la nécessité. Tu te poses une question et ils te généraient, sur la météo par exemple, ils te généraient un composant du high, d'interface graphique, à la volée. Ils voit le budget. En fait, la question, c'est une question en back-end et en front-end.
[1167.98s - 1169.54s]  En back-end, c'est quels outils appeler
[1169.54s - 1172.22s]  pour aller chercher de l'information ou pour actionner des choses.
[1172.72s - 1174.20s]  Et en front-end, c'est quelle interface
[1174.20s - 1176.60s]  il faut montrer à l'utilisateur étant donné son intention actuelle.
[1177.06s - 1178.70s]  Et ce que ça veut dire, c'est que les gros logiciels
[1178.70s - 1179.92s]  avec 50 000 boutons,
[1180.22s - 1182.74s]  je pense notamment au montage, ça va progressivement disparaître
[1182.74s - 1225.78s]  parce que tu peux identifier son état d'esprit au moment où il est en train de créer et adapter les boutons, lui donner exactement ce dont il a besoin. Et donc ça change vraiment complètement la manière dont les interfaces vont se comporter dans les années qui viennent. Justement, on parlait de cette interface, de comment on y accède. Tu parlais du fait que vous êtes déployable un peu de n'importe où. Il y a un truc que moi je constate en parlant autour de moi, c'est qu'on a un peu une génération d'employés d'entreprises frustrés actuellement parce que chez eux, ils peuvent utiliser des trucs incroyables, genre les meilleurs modèles disponibles, ils vont sur OpenAI, etc. Une fois au travail, on leur interdit souvent l'utilisation des meilleurs outils et parfois, ils se retrouvent avec des versions un peu bridées ou des copilotes. Ou avec rien du tout.
[1225.86s - 1227.56s]  Ou avec, pour la plupart du temps, rien du tout.
[1228.16s - 1230.56s]  Ça vient d'où, ça ? Ça vient du fait que
[1230.56s - 1231.96s]  les systèmes DI
[1231.96s - 1233.90s]  génératifs, ça touche beaucoup aux données.
[1234.24s - 1235.94s]  Et les données dans les entreprises, c'est quand même assez important.
[1236.32s - 1238.26s]  Et donc, c'est là-dessus
[1238.26s - 1239.98s]  que nous, on a cherché à trouver des solutions.
[1240.38s - 1242.52s]  Faire en sorte que les données, elles restent dans l'entreprise,
[1242.94s - 1244.44s]  que nous, en tant que fournisseurs
[1244.44s - 1487.32s]  d'AI, on n'est pas à avoir ces données ces données là ça permet justement d'avoir le niveau de sécurité, le niveau de gouvernance dont tu as besoin sur les données et donc progressivement on va résoudre ce problème et nous je dirais que c'est un des problèmes essentiels qu'on cherche à résoudre faire en sorte que l'IT dans les entreprises soit confortable pour amener le chat à tous leurs employés et qu'ils arrêtent d'être frustrés Dans les exem exemples d'outils que tu donnais, il y a un truc qui revient, qu'on n'a pas explicité mais qui est en fait super important, c'est la notion d'objectif. D'avoir un mode des modèles qui sont capables d'effectuer des tâches et sur la route d'arriver à créer des étapes et à appeler les bons outils comme le ferait un bon stagiaire. Tu n'as pas nécessairement à lui expliquer l'ensemble des étapes qu'il doit faire. Tu lui dis, regarde les prochains vols pour New York et prends-en un. Tu n'as pas besoin de lui expliquer étape par étape, seconde par seconde, ce qu'il doit effectuer. Aujourd'hui, on a des modèles qui peuvent commencer à appeler des outils, mais qu'on sent un peu limités dans leur capacité à en utiliser plusieurs d'affilés, notamment. Des trucs vraiment utiles, vraiment stylés. Comment tu penses que ça va évoluer ? Est-ce que c'est une frontière qui peut être bientôt franchie ? Est-ce que l'année prochaine on aura résolu ce problème et on pourra faire 20 étapes avec beaucoup de fiabilité ? Ou est-ce qu'on est encore loin d'y arriver ? Je pense que c'est la frontière. Tout le monde essaie de la pousser, ça ne va pas se débloquer d'un coup. Parce qu'en fait, maer un outil ça prend du temps à un humain ça prend aussi du temps à un modèle il faut des démonstrations il faut du feedback parce que la première fois il va se tromper et une notion d'expertise qu'il faut distiller de l'entreprise vers les systèmes d'AI et ça, ça va pas se faire de manière magique il faut tous les systèmes en place il faut les métasyst'est-à-dire qu'il faut que les employés dans les entreprises soient capables de fournir du signal supplémentaire au système d'AI pour qu'il s'améliore. Donc ça va progresser. On va avoir de plus en plus d'outils utilisables en même temps et des modèles qui peuvent résonner de plus en plus. Mais ça va être progressif. Et pour que ça marche vraiment très bien, il faut y mettre du sien et investir dès maintenant. Pour illustrer ça, on voit que OpenAI, dans leur dernier modèle, dans les O1 et compagnie, c'est plus des améliorations significatives sur le modèle en lui-même, mais ils tentent des trucs de le faire boucler sur lui-même, faire des chaînes de pensée, je ne sais pas comment on dit en français. Chaîne de pensée, oui. C'est pas mal, non ? Est-ce que, selon toi, c'est un peu un signe qu'on a atteint une sorte de plafond ? C'est-à-dire que, justement, sur cette évolution exponentielle, on a bien optimisé par rapport à leur taille la manière dont marchent les modèles. Maintenant, justement, il faut trouver autre chose. C'est un paradigme qui est de plus en plus saturé. Je pense qu'il n'est pas encore saturé, qui est ce qu'on appelle le préentraînement, donc la compression de la connaissance humaine. De certaines manières, tu as une connaissance disponible humaine humaine qui a une certaine taille, à un moment tu as fini de la compresser et c'est là où il faut aller chercher du signal supplémentaire. Chaîne de pensée, utilisation de plusieurs outils, utilisation de signal experts dans les entreprises. Il n'y a pas de saturation du système, on sait comment aller à l'étape suivante mais sur l'aspect pré-entraînement, oui on commence à savoir bien le faire collectivement, tout le monde sait à peu près faire la même chose et donc c'est plus tellement là où est la compétition, la compétition elle est sur les interfaces et la compétition elle est sur avoir des modèles qui tournent pendant plus longtemps. Je trouve que c'est un peu dur de se faire un avis dessus justement quand on ne maîtrise pas la stack scientifique entre guillemets derrière les transformers et compagnie mais j'ai l'impression qu'il y a un peu ce débat entre est-ce que c'est juste une question de compute, de données, qui va repousser cette barrière d'autonomie ou est-ce que c'est vraiment un problème intrinsèque à la manière dont le modèle est designé ? Et que juste le fait que ce soit de la prédiction du prochain token qui peut avoir un petit pourcentage de partir en cacahuète à chaque fois, ça rend nécessairement trop compliqué, trop difficile la planification long terme. Je sais que par exemple, il y a des gens comme Yann Lecay, on en parle souvent, qui sont un peu défenseurs de cette vision-là que l'AGI, ou je ne sais pas comment on l'appelle, elle est cachée encore derrière des découvertes scientifiques. Oui, c'est une bonne question. Ce qui est vrai, c'est que travailler sur des architectures qui
[1487.32s - 1489.78s]  induisent des biais de réflexion
[1489.78s - 1491.52s]  humaine, c'est souvent utile. Ça a été
[1491.52s - 1493.68s]  utile pendant les 12 dernières
[1493.68s - 1495.88s]  années, de se dire, comment nous on réfléchit,
[1496.08s - 1497.34s]  essayons d'écrire ça
[1497.34s - 1499.54s]  en mathématiques, et de faire en sorte que les
[1499.54s - 1501.58s]  modèles copient un peu ce qu'on sait faire.
[1502.40s - 1504.00s]  Ce qu'on observe aussi, c'est que
[1504.00s - 1525.88s]  toute l'intelligence qu'on peut mettre dans les architectures, il suffit de mettre deux fois plus de compute et ça disparaît. Donc, en fait, le paradigme qu'on a suivi dans les cinq dernières années, c'est plutôt de se dire prenez une architecture extrêmement simple, qui prédit des séquences, et passons-là à l'échelle, allons chercher le plus de données possibles, allons chercher les données multimodales, allons chercher de l'audio, ce genre de choses, et passons-la à l'échelle
[1525.88s - 1527.80s]  et voyons ce que ça donne. Et en fait, ce que ça donne,
[1527.92s - 1530.08s]  c'est que c'était en tout cas plus intelligent
[1530.08s - 1531.32s]  en termes d'allocation de ressources
[1531.32s - 1533.66s]  de travailler sur un passage à l'échelle que de travailler
[1533.66s - 1535.30s]  sur des architectures subtiles.
[1535.92s - 1537.78s]  Alors, est-ce que c'est toujours le cas, maintenant,
[1537.86s - 1539.86s]  comment ça va avoir saturé la quantité de données
[1539.86s - 1542.12s]  qu'on s'est compressées ? Je pense que la question est ouverte.
[1542.86s - 1543.80s]  Le sujet, c'est plus tellement
[1543.80s - 1645.28s]  une question d'architecture, c'est plutôt une question d'orchestration. C'est-à-dire, comment on fait, effectivement, pour que les modèles se rappellent eux-mêmes, qu'ils interagissent avec des outils, qui durent longtemps, qu'ils fassent du raisonnement en plusieurs étapes. Et ça, ça reste les mêmes modèles, au fond. C'est la brique de base, mais le système complet, c'est pas juste le modèle, c'est le modèle qui sait se rappeler lui-même, qui sait réfléchir, qui sait interagir avec tout son environnement, qui sait interagir avec les humains. Donc la complexité des systèmes, elle devient beaucoup plus grande que juste un simple modèle de génération de séquences. Ça reste le moteur, mais ce n'est pas du tout toute la voiture. Mais donc, tu es plutôt optimiste sur le fait que ce soit le bon moteur. C'est le bon moteur. Après, il y a une règle en machine learning qui dit essentiellement, augmenter la capacité de calcul, ça augmente la qualité des systèmes. Et tu as deux solutions pour le faire. Soit tu compresses de la donnée, soit tu fais de la recherche. C'est-à-dire que tu vas échantillonner, tu vas demander au modèle de tester mille trucs et de sélectionner l'échantillon qui marche le mieux et tu vas le renforcer là-dessus. Et donc là, on commence de plus en plus à basculer dans le mode recherche plutôt que dans le mode compression. La personne qui a dit ça, c'est Richard Sutton, dans un blog post que je vous invite à lire, qui s'appelle The Beater Lesson. Est-ce que toi, il y a une démo, un peu de bout en bout, d'un truc qui a, même si parfois ça marche pas, etc., mais d'un truc où t'as été impressionné, où ça a vraiment très bien marché, d'une suite d'étapes, un truc qui t'a fait un peu sentir comme Iron Man, avec Jarvis. Oui, avec le chat, on a connecté les API ouvertes de Spotify, tu peux lui parler, lui demander des playlists, décrire ta playlist, ça te crée ta playlist et ça la joue pour toi. C'est juste un seul outil, ça. Là où on a vu des choses très intéressantes. Une fois qu'on a connecté le web,
[1645.80s - 1647.84s]  ça te permet d'avoir toutes les informations en live.
[1648.30s - 1649.64s]  Et très vite, tu peux te créer tes mémos
[1649.64s - 1651.70s]  pour savoir qu'est-ce qu'il faut aller dire à tel client en fonction
[1651.70s - 1653.56s]  des informations qu'il a eues. Et donc,
[1653.84s - 1656.06s]  la combinaison des outils, ensemble,
[1656.38s - 1657.94s]  ça fait émerger des cas d'usage que tu n'avais pas
[1657.94s - 1659.78s]  forcément prévus. Si tu as connecté
[1659.78s - 1661.68s]  le web, si tu connectes ton mail, tu peux faire
[1661.68s - 1663.82s]  plein de choses en même temps. Et si tu connectes
[1663.82s - 1705.68s]  ta connaissance interne et le web, tu peux combiner ces informations de manière un peu imprévisible. Et donc, la quantité de cas d'usage que tu couvres est à peu près assez exponentielle au nombre d'outils. Et donc, ça, c'est assez magique, je veux dire. Moi, effectivement, je trouve qu'il y a un côté un peu vertigineux. On va pouvoir construire des trucs de fou. Mais du coup, ça fait que c'est un peu dur de s'imaginer, de se dire, ça va ressembler à quoi concrètement ? Le métier de développeur, de quelqu'un qui doit faire des scénarios de LLM, justement, ça ressemble à quoi ? Je dirais que c'est un outil qui augmente le niveau d'abstraction requis par les humains. En tant que développeur, tu vas continuer à réfléchir aux problèmes que tu cherches à résoudre pour tes utilisateurs.
[1706.08s - 1708.08s]  Tu vas continuer à réfléchir aux architectures
[1708.08s - 1712.24s]  au niveau qui remplissent tes contraintes,
[1712.28s - 1712.96s]  ton cahier des charges.
[1713.42s - 1714.98s]  Après, est-ce que tu vas continuer
[1714.98s - 1717.08s]  à coder tes applications en JavaScript ?
[1717.08s - 1717.90s]  Vraisemblablement, non,
[1717.96s - 1719.32s]  parce que les modèles arrivent bien
[1719.32s - 1721.44s]  à générer des applications simples
[1721.44s - 1723.08s]  et des applications de plus en plus compliquées.
[1723.58s - 1745.84s]  Donc, tous les sujets très abstraits qui vont nécessiter de la communication avec des humains. Le métier d'ingénieur, c'est aussi un métier de communication. Il faut aussi comprendre quelles sont les contraintes de chacun. Ça, ça ne va pas être facilement remplaçable. Mais en revanche, tout l'aspect « je t'aide à faire tes tests unitaires », « je te fais ton application Pixel Perfect », à partir d'un design, ça je pense que ça devait devenir de plus en plus automatisable
[1745.84s - 1747.34s]  pour juste coller
[1747.34s - 1750.00s]  aux développeurs, mais c'est le cas pour
[1750.00s - 1751.94s]  tous les métiers. Est-ce qu'on a une intuition
[1751.94s - 1754.14s]  de comment ça se fait que les modèles, ils sont aussi
[1754.14s - 1756.02s]  sensibles au code ?
[1756.02s - 1757.98s]  Est-ce qu'on pourrait se dire, par exemple, je veux un modèle qui est
[1757.98s - 1759.28s]  super fort en français et en anglais,
[1760.20s - 1761.74s]  pour qu'ils sachent le Python et le JavaScript,
[1761.88s - 1763.98s]  a priori, ça n'est pas utile. Or, c'est
[1763.98s - 2046.16s]  pas du tout ce qu'on observe, de ce que j'ai compris. Alors, c' très bonne question. C'est vrai qu'on observe un genre de transfert. C'est-à-dire qu'entraîner son modèle sur beaucoup de codes, ça lui permet de raisonner mieux. Je ne suis pas le mieux placé pour en parler, il faudrait que ça soit plutôt Guillaume, mais la réalité, c'est que le code, ça a plus d'informations que le langage. Il y a plus de réflexion qui est passée dans le langage,'est plus structuré et donc s'entraîner à générer du code ça force le modèle à résonner à plus haut niveau que l'entraîner à générer du texte et donc il sait résonner sur du code et donc quand il voit du texte il sait aussi résonner sur du texte et c'est vrai qu'il y a ce transfert un peu magique qui est je pense une des raisons pour lesquelles les modèles sont devenus largement meilleurs dans les deux dernières années. Ça sert aussi parce que, en fait, t'as beaucoup plus de code base qui sont plus longs qu'un livre. Comprendre une code base, c'est plus long que lire un livre. Et donc, un peu le maximum sur lequel tu peux t'entraîner pour faire un modèle qui comprend le contexte long, c'est des livres du 19e siècle. Et le maximum sur lequel tu peux t'entraîner pour faire du code, c'est des millions de lignes de projets open source. Et donc, c'est plus long et ton modèle peut résonner plus longtemps. Je pense que c'est une des intuitions. Je te propose de parler maintenant un petit peu de talent et des gens qui font que vous faites ce que vous faites. Déjà, pourquoi est-ce que vous avez décidé, à la base, de mettre Mistral à Paris ? Aujourd'hui, ça peut paraître un peu plus évident, entre guillemets, on sait que l'écosystème est super vivant, justement, on va en parler. Mais est-ce que c'était une décision à cette époque-là, une décision évidente entre ce maître-là ou à San Francisco, même avec une boîte française, entre guillemets ? On ne s'est même pas posé la question en réalité. Moi, je n'avais aucune envie de partir de Paris. Ma compagne est fonctionnaire, donc elle a quelques contraintes. Timothée, il n'avait aucune envie de partir de France aussi, et Guillaume non plus. Je pense qu'en réalité, si j'ai réfléchi, je crois qu'on ne s'est jamais posé la question. On savait aussi que les gens dans notre réseau, en fait, c'est des Parisiens, des Parisiens, des gens à Londres aussi, ces personnes qu'on pouvait recoter, c'était des gens locaux. Donc c'était une évidence de démarrer à Paris. Comment ça se fait, ça ? Que Paris, particulièrement, fourmille autant de bons ingés et scientifiques ? Je pense parce qu'il y a un écosystème en machine learning. Il y a un écosystème avec l'INRIA, avec l'Académique d'un côté, et puis les laboratoires privés que Yann Lequin a contribué à créer. T'as un laboratoire FAIR, historiquement, qui avait été créé en 2015, je pense. T'as DeepMind, qui, en réaction, s'était installé là-bas, et qui avait un énorme centre de compétences à Londres grâce à DeepMind. Et donc, en fait, ce qui fait les talents dans la tech, c'est le fait que t'es une entreprise qui soit déjà passée par là avant qui a grossi et que t'es des gens qui ont appris dans cette entreprise là et qui ensuite essaiment et donc on a bénéficié de ça, on a bénéficié des entrepreneurs qui voulaient bien nous rejoindre et qui se sont formés là-bas très bon écosystème privé et très bon écosystème public aussi parce qu'il y a beaucoup de nos chercheurs qui ont fait des thèses dans l'académique en France aussi. Le résultat est assez dingue quand même, parce que rien que les conventions d'hier, j'ai vu Oliama par exemple, qui a organisé un meet-up ou un truc comme ça, et tu vois les images, on ne se dit pas que ça apparaît, et en fait, ça bouge de fou. Il y a plein de gens dans ce domaine en particulier qui sont des Français. Yann Lequin est un Français, mais en dessous des gens plus jeunes que lui, il y a beaucoup de gens qui ont fait... Sialon, par exemple. Oui, par exemple. À Meta, Paris, il y a aussi des gens très forts. À DeepMind, Paris, il y a des... Je n'ai pas encore réussi à débaucher pour l'instant. Je pense qu'on a débauché les gens qu'on pouvait. Ah, c'est terminé, c'est... J'ai plein d'amis qui sont français, qui sont encore là-bas. Ils finiront peut-être par créer leur boîte. De manière générale, l'Europe et la France en particulier ont les bonnes compétences. Il y a les bonnes écoles. Il faut être fort en maths et fort en informatique pour faire scientifique en intelligence artificielle. Et de fait, on a les bons tuyaux de formation. Et c'est quoi les arguments aujourd'hui ? Moi, je viens de sortir de ma thèse en ML. Qu'est-ce qui fait, d'après toi, que je vais plutôt décider d'avenir chez Mistral versus chez Meta ou chez DeepMind ? En sortant de Master, à Paris, je pense qu'on est de loin le meilleur centre de formation pour faire le cœur de la science en intelligence artificielle. Il n'y a pas de structure équivalente, même en Europe, sur ce qu'on fait. Il y a 50-60 scientifiques chez nous qui sont tous extrêmement bien formés. Et donc, en sortant de Master, je trouve que c'est le meilleur endroit, parce qu'en 6 mois, ils sont formés. C'est aussi un excellent endroit pour nous, parce qu'on va récupérer des gens juniors. On a une bonne marque avec eux, on leur propose une excellente formation. Ils nous rejoignent et en fait, ils sont très performants au bout de 6 mois mois. Ils ont plein d'idées, ils sont extrêmement créatifs, ils ont 23 ans,
[2046.24s - 2047.20s]  ils ont toute l'énergie qu'il faut.
[2048.06s - 2049.94s]  On les utilise, on doit
[2049.94s - 2051.74s]  beaucoup de ce qu'on a proposé
[2051.74s - 2052.90s]  à des gens qui sont très jeunes.
[2053.90s - 2055.78s]  On encourage tous les gens en master à venir
[2055.78s - 2058.08s]  nous rejoindre. On a plein de places et on adore
[2058.08s - 2059.84s]  les former. J'ai appris tout à l'heure
[2059.84s - 2062.04s]  d'ailleurs qu'après notre émission qu'on avait
[2062.04s - 2063.94s]  faite sur Mistral, il y a eu une recrue.
[2064.26s - 2066.08s]  Tu te souviens, tu ne sais pas quel genre de profil ?
[2066.08s - 2068.02s]  Si, c'est un ingénieur. Ce n'est pas un scientifique,
[2068.16s - 2069.56s]  c'est un ingénieur. Ça va ? Tout va bien ?
[2069.56s - 2040.00s] 
[2327.24s - 2329.24s]  on a pas... C'est-à-dire qu'après notre émission qu'on avait faite sur Mistral, il y a eu une recrue. Tu te souviens ? Tu ne sais pas quel genre de profil ? Si, c'est un ingénieur. Ce n'est pas un scientifique, c'est un ingénieur. Tout va bien, on n'a pas envie. Oui, très content. Ok, parfait. Tu conseillerais quoi, toi, à des gens qui sont peut-être moins avancés ou qui réfléchissent à ce qu'ils veulent faire, qui voient bien qu'il y a quelque chose qui se passe dans l'IA ? Est-ce que, d'après toi, c'est trop tard, entre guillemets, dans le sens où ça va être un écosystème très saturé ? Ou est-ce que tu penses que c'est encore possible ? Et qu'est-ce que tu conseillerais comme choix d'études, de trucs à explorer ? Est-ce qu'il faut faire des modèles de langage comme tout le monde ? Ou est-ce que, justement, il faut essayer de sortir un petit peu de la bulle ? C'est quoi ton conseil ? Non, je pense qu'il faut réfléchir aux systèmes qu'on crée avec. Nous, on crée des systèmes de gestion de la connaissance, mais il y a plein de systèmes verticalisés dans les sciences de la vie, dans l'architecture, dans la conception par ordinateur, qui ne demandent qu'à être pris avec des nouveaux systèmes. Le montage vidéo, aussi. Et donc, se dire que la technologie, elle va continuer à avancer, les technologies horizontales, elles vont être de plus en plus performantes, ça ouvre de nouvelles opportunités d''automatisation de nouvelles opportunités de création de logiciels intéressants, de création de services complètement différents pour les utilisateurs et donc partir des besoins utilisateurs partir un peu du rêve du logiciel de demain la machine auquel on va parler et qui va faire tout ce qu'on veut à sa place je pense que c'est un bon point de départ on choisit sa verticale et puis on se dit, est-ce que les modèles aujourd'hui peuvent résoudre ce problème ? S'ils ne peuvent pas résoudre ce problème, peut-être qu'il faut les personnaliser, peut-être qu'il faut aller un petit peu plus profondément. Et là-dessus, on peut aider à le faire. On a tous les outils qui permettent de faire les personnalisations verticalisées. Nous, on a parlé avec Microsoft des conséquences que ça avait dans la recherche de matériaux, par exemple. Et tu te dis, mais c'est quoi la base ? On parle de modèles qui génèrent des images, du texte, etc. Et en fait, on découvre des... Grâce à ça, entre autres, on découvre des matériaux. Est-ce qu'il y a, toi, des trucs comme ça, soit dans vos partenaires actuels ou dans les trucs que toi, t'as vus, qui t'ont aussi frappé ? La découverte de matériaux, c'est les mêmes techniques, c'est pas les mêmes modèles. Parce qu'en fait, ce qu'on fait, c'est qu'on séquence, de manière générale, il y a plein de problèmes qui se résolvent en séquençant, en sérialisme de manière générale le problème. La découverte de matériaux, c'est de la chimie, donc on peut sérialiser les molécules chimiques et demander au modèle de les prédire. Après, le paradigme, je prédis des séquences, et j'ai plein de séquences sous la main de données particulières, ils marchent en chimie, ils marchent en médecine, ils marchent certainement enement en sciences de la vie aussi. On ne travaille pas là-dessus, mais on est ravis d'être partenaire avec des startups qui font ça. Et là où, peut-être, comme tu disais, on arrive à une fin d'exponentiel éventuellement sur le texte, il y a peut-être plein d'autres domaines où le transfert ne fait que commencer. Sur le texte, on n'est pas du tout à saturation puisque la prochaine étape, c'est d'avoir des modèles qui appellent plein d'outils. Du coup, ils deviennent beaucoup plus intelligents que juste des générateurs de texte. Et un des outils qu'ils peuvent appeler, c'est des simulateurs, par exemple. Donc la boucle de travail du concepteur de turbine, de la personne qui travaille sur un nouveau médicament, elle va complètement changer dans les années qui viennent. Et ça vient à la fois des modèles spécialisés de prédiction de molécules, par exemple, mais ça vient aussi de l'interface avec la connaissance qu'on est en train de recréer. Tu vas pouvoir parler avec ton ordinateur et dire est-ce que tu peux me simuler une turbine qui ressemble à celle-là mais un peu plus grande, et fais-moi plusieurs essais et dis-moi la celle qui marcherait la mieux. Et donc, la manière d'itérer, l'ingénierie, finalement finalement ça va aussi beaucoup changer de nature dans les années qui viennent c'est hyper intéressant parce qu'effectivement les trucs auxquels on pense rapidement c'est tu parlais de simulateur il y a le simulateur de code tout simplement c'est des trucs qui se font un peu déjà c'est le plus facile à simuler puisque ça reste au sein de la machine il n'y a pas de monde extérieur et donc on voit déjà un peu une sandbox par exemple qui peut exécuter un bout de code et on voit si ça marche si ça ne marche pas ça cest des trucs qui existent. Le raisonnement et le fait d'avoir un modèle qui génère du code qui est ensuite exécuté, on y travaille pour très prochainement. Et donc, c'est une grosse porte d'entrée vers des cas d'usage complexes. Tu as un espace ouvert d'outils à appeler maintenant. Parce que tes outils, c'est tes librairies. Le niveau de contrôle aussi que tu dois mettre sur les modèles, ça devient plus compliqué à évaluer, parce que c'est plus ouvert, plus le monde est ouvert c'est difficile à évaluer, mais clairement on va vers ça un modèle avec un exécuteur de code, c'est beaucoup plus performant qu'un modèle sans exécuteur de code Dès qu'on commence à parler d'outils, d'exécuter des trucs du code, moi j'entends tout de suite d'autres profils dans l'écosystème de l'IA qui sont dans la frangeange très alarmiste de comment pourrait évoluer l'IA et des possibilités
[2329.24s - 2330.84s]  qu'une IA devienne rogue
[2330.84s - 2332.42s]  et prenne son indépendance.
[2332.58s - 2333.72s]  Tu parles d'exécuter du code,
[2334.36s - 2336.32s]  on l'imagine sortir de la boîte.
[2336.64s - 2337.78s]  C'est quoi, toi, ton avis là-dessus ?
[2337.78s - 2339.78s]  Est-ce que, pour être caricatural,
[2339.88s - 2341.82s]  c'est un peu un moyen
[2341.82s - 2343.82s]  de mettre en place des régulations
[2343.82s - 2345.64s]  pour qu'elle nassez tout ça ?
[2345.64s - 2346.72s]  Ou est-ce qu'il y a vraiment
[2346.72s - 2348.62s]  des questions à se poser ?
[2348.62s - 2349.90s]  Il y a des questions à se poser
[2349.90s - 2320.00s] 
[2425.12s - 2427.24s]  c'est aléatoire, ça dépend de l'entrée, tu ne peux pas, en tant qu'humain, prédire ce que le modèle va sortir. Tu veux quand même faire du logiciel avec. Un logiciel, par essence, avant de le mettre à disposition du marché, tu veux vérifier qu'il couvre tous tes cas et qu'il n'y a pas de bug. Et donc la question de faire en sorte que ton système qui repose sur des LLM n'ait pas de bug, c'est une question difficile. C'est une question de contrôle, c'est une question d'évaluation. Et finalement, pour nous, la question de sûreté, en anglais c'est safety, c'est d'abord une question d d'évaluation c'est d'abord une question d'avoir les bons outils pour vérifier que ça fonctionne et si ça ne fonctionne pas, avoir les bons outils pour corriger ça. Un des outils qu'on met à dispo et qui est utile pour ça c'est si tu veux contraindre l'espace des possibles de ton modèle et de ton système tu contrains l'espace des entrées donc tu mets une modération sur le type de questions que l'utilisateur peut poser, et comme ça, soudain tu passes d'un système qui peut répondre à toutes les questions, à un système qui peut répondre que aux questions qui sont intéressantes pour le logiciel que tu crées. Et donc, pour nous, on voit vraiment l'aspect sûreté au niveau du système lui-même et comme un problème d'intégration continue, comme un problème de test, il faut répondre à la question, comment on construit des logiciels déterministes qui tournent sur des systèmes
[2427.24s - 2428.22s]  fondamentalement stochastiques.
[2428.60s - 2429.38s]  Ça, c'est la première chose.
[2429.76s - 2431.38s]  Ensuite, oui, il y a de la science-fiction.
[2432.48s - 2434.60s]  Et puis, tu as quelques entreprises
[2434.60s - 2435.90s]  aux Etats-Unis qui ont un intérêt
[2435.90s - 2437.72s]  à dire aux régulateurs
[2437.72s - 2439.54s]  écoutez, cette technologie,
[2439.64s - 2440.80s]  elle est quand même un peu trop compliquée,
[2440.94s - 2442.14s]  un peu trop difficile à comprendre,
[2442.56s - 2443.42s]  un petit peu trop dangereuse.
[2443.52s - 2446.10s]  Imaginez que le truc devienne indépendant.
[2446.46s - 2447.24s]  Bon, tu vas dire ça à des gens
[2447.24s - 2448.10s]  qui ne comprennent pas forcément
[2448.10s - 2449.14s]  exactement ce qui se passe.
[2449.14s - 2449.92s]  Ils peuvent se dire
[2449.92s - 2420.00s] 
[2525.14s - 2526.84s]  ... un peu trop compliqué, un peu trop difficile à comprendre, un petit peu trop dangereuse, imaginer que le truc devienne indépendant. Tu vas dire ça à des gens qui ne comprennent pas forcément exactement ce qui se passe, ils peuvent se dire, ah oui, peut-être que si on donnait ça à trois personnes, ou à deux personnes, aux Etats-Unis, on contrôlerait tout ce qui se passe, et puis il n'y a pas de problème. Mais nous, on pense que c'est faux, c'est-à-dire qu'avoir deux entités, ou encore pire, une entité qui contrôle tous les systèmes et qui ouvre sa porte à des auditeurs auxquels ils montrent ce qu'ils veulent, on pense que ce n'est pas la bonne solution. La bonne solution, en sûreté logicielle, c'est l'open source de manière générale. On l'a montré en cyber, on l'a montré sur les systèmes les plus fiables aujourd'hui, les operating systems les plus fiables, c'est Linux. Le fait d'avoir le plus d'yeux possible sur une technologie, le fait de la distribuer le plus possible, c'est une manière de faire en sorte que le contrôle de cette technologie soit sous un contrôle démocratique. Et donc, nous c'est ce qu'on dit. Et puis quand on entend les doomers raconter autre chose, il y a des gens qui sont de bonne foi. Il faut le reconnaître, qu'ils ont vraiment peur que ce sont des choses qui vont se passer. Et puis il y a surtout beaucoup de gens qui ne sont pas du tout de bonne foi. Je pense qu'il est important de vérifier d'où ils viennent. Ça ne doit pas être simple, parce qu'en face, l'argument, il est super facile à comprendre, justement, comme tu disais, pour quelqu'un qui n'est pas forcément adepte du sujet, on te dit voilà un outil dangereux, est-ce qu'il ne faudrait pas éviter qu'on le mette dans trop de mains ? Tu pars déjà avec un truc un peu dur à défendre. On a un atout historique.
[2527.80s - 2529.98s]  Ce n'est pas la première fois qu'on a ce débat. On a eu ce débat pour
[2529.98s - 2532.18s]  l'Internet. Internet, ça aurait pu être un truc contrôlé
[2532.18s - 2534.08s]  par trois entreprises qui auraient
[2534.08s - 2536.08s]  fait leur propre net, qui auraient refusé
[2536.08s - 2537.90s]  de standardiser les choses. Et en fait,
[2538.10s - 2539.92s]  finalement, il y a eu suffisamment de pression.
[2540.40s - 2542.04s]  À un moment donné, le régulateur s'est dit
[2542.04s - 2544.22s]  on va faire en sorte qu'elle soit standardisée.
[2544.58s - 2686.00s]  Et donc Internet, ça appartient à tout le monde maintenant. Il aurait suffi que des personnes différentes fassent des choix différents quelques personnes et on serait dans une situation où en fait il y a trois wall garden non interopérables ça aurait pu être la même chose pour le end-to-end encryption ça c'est un autre exemple, à une époque c'était considéré comme une arme et c il y avait un contrôle des exports des Etats-Unis. Ce qui paraît fou, maintenant. En fait, on se pose la question maintenant sur les poids. Parfois, il y a certains régulateurs qui se posent cette question-là. Mais ça paraît fou pour le end-to-end encryption. Ce qu'on pense, c'est que dans 10 ans, ça paraîtrait complètement fou pour des poids d'un modèle. Parce que c'est tellement infrastructurel, c'est tellement une ressource qui doit être partagée par tout le monde, cette compression de la connaissance et cette intelligence, que pour nous, c'est criminel de la laisser entre les mains de deux entités qui ne sont pas du tout sous contrôle démocratique. Et pour défendre cette vision-là que, du coup, le contrôle doit avoir lieu un peu plus tard dans la chaîne, au moment de l'interface, par exemple, ou par l'entreprise vis-à-vis de son client, tu vas notamment au Sénat. On t'a vu sur YouTube parler au Sénat. Ça fait quoi de parler, d'essayer d'expliquer ce que c'est un modèle, un dataset, un LLM à des sénateurs ? C'est intéressant. C'est un exercice. Il y avait des bonnes questions, peut-être posées par des gens qui comprenaient un peu moins la technologie, on va dire, mais je pense que c'est important. De manière générale. C'est des représentants des citoyens et il faut qu'ils comprennent que c'est une technologie qui va affecter les citoyens. Donc nous, on est prêts à investir du temps parce que mieux c'est compris, plus on comprend que c'est aussi un enjeu de souveraineté, c'est aussi un enjeu culturel. C'est un enjeu d'avoir des acteurs comme nous et pas que nous, mais des acteurs comme nous sur le sol européen. Parce que si ce n'est pas le cas, en fait, le sujet, c'est qu'on a une dépendance économique énorme aux Etats-Unis, et ça, elle est très très dommageable à long terme. Et donc le fait d'aller parler aux gens qui font les lois, aux gens qui, derrière, vont aussi parler avec leurs citoyens, comprennent leurs angoisses, etc., c'est une manière de dédramatiser cette technologie. C'est une technologie qui va apporter beaucoup de bénéfices dans l'éducation, dans la santé, dans la manière dont on travaille. Et il faut que les représentants de la démocratie française, de la démocratie européenne, de la démocratie américaine aient conscience, savent de quoi il s'agit. Moi, je dois dire que personnellement, je n'avais pas tellement prévu de faire ça en démarrant la boîte, mais il faut faire entendre savoir parce que sinon, le vide est comblé par des gens qui n'ont pas
[2686.00s - 2687.96s]  forcément des intérêts alignés
[2687.96s - 2689.54s]  avec la démocratie
[2689.54s - 2691.98s]  et certainement pas alignés avec ce que nous, on essaie de faire.
[2692.18s - 2693.78s]  Si vous n'avez pas suivi l'histoire du
[2693.78s - 2696.20s]  Vesuvius Challenge, ou comment un papyrus
[2696.20s - 2697.94s]  a été décrypté par un étudiant
[2697.94s - 2699.68s]  en IA, allez voir cette vidéo, c'était
[2699.68s - 2700.62s]  vraiment passionnant.

